Traceback (most recent call last):
  File "/home/sam/code/ucsc/243/admire/admire-finetuning-sam/v2/train.py", line 311, in <module>
    main()
  File "/home/sam/code/ucsc/243/admire/admire-finetuning-sam/v2/train.py", line 282, in main
    generated_text = generate_text_from_sample(peft_model, processor, sample)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sam/code/ucsc/243/admire/admire-finetuning-sam/v2/train.py", line 146, in generate_text_from_sample
    model_inputs = processor(
                   ^^^^^^^^^^
  File "/home/sam/code/ucsc/243/admire/admire-finetuning-sam/venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/processing_qwen2_vl.py", line 115, in __call__
    image_inputs = self.image_processor(images=images, videos=None, **output_kwargs["images_kwargs"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sam/code/ucsc/243/admire/admire-finetuning-sam/venv/lib/python3.12/site-packages/transformers/image_processing_utils.py", line 41, in __call__
    return self.preprocess(images, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Qwen2VLImageProcessor.preprocess() got an unexpected keyword argument 'image_size'
