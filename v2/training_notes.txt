Training run on Dec3 overnight (7b 4bit Lora)
https://wandb.ai/sam-silver/qwen2-7b-instruct-trl-sft/runs/x017i311?nw=nwusersamsilver
Uploaded to
https://huggingface.co/UCSC-Admire/Qwen2-VL-7B-Instruct-finetune-2024-12-04_02-08-26
It's just the LoRA adapters, not the full model.

Trained using:
def main():
    # Load training dataset
    print("Loading dataset...")
    dataset = load_dataset(DATASET_NAME, split="train")
    print(f"Dataset size: {len(dataset)}")
    dataset_dict = dataset.train_test_split(test_size=0.05, seed=42) # Use 5% of the training split as evaluation
    print("Processing datasets...")
    # train_dataset = dataset_dict["train"].map(
    #     format_data,
    #     batched=False,
    #     # batch_size=32,
    #     num_proc=1,
    #     remove_columns=dataset_dict["train"].column_names,
    #     load_from_cache_file=False,  # Disable caching
    #     keep_in_memory=False # Not sure what this does yet, but o1 thinks it exists and matters?
    # )
    # print(f"Mapped training data")
    # eval_dataset = dataset_dict["test"].map(
    #     format_data,
    #     batched=False,
    #     # batch_size=32,
    #     num_proc=1,
    #     remove_columns=dataset_dict["test"].column_names,
    #     load_from_cache_file=False,  # Disable caching
    #     keep_in_memory=False # Not sure what this does yet, but o1 thinks it exists and matters?
    # )
    # print(f"Mapped evaluation data")
    # print(f"Train dataset size: {len(train_dataset)}")
    # print(f"Eval dataset size: {len(eval_dataset)}")

    # Process the datasets
    # print("Processing datasets...")
    train_dataset = dataset_dict["train"]
    test_dataset = dataset_dict["test"]
    train_dataset = [format_data(sample) for sample in tqdm(train_dataset, desc="Processing train data")]
    eval_dataset = [format_data(sample) for sample in tqdm(test_dataset, desc="Processing eval data")]

    # Create Bits and Bytes Config
    # The model's weights are quantized to 4-bit, but the computations (activations, gradients) are done in bfloat16 for better numerical stability. 
    # This combination gives you both memory efficiency (from 4-bit quantization) and training stability (from bfloat16 compute).
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type="nf4", bnb_4bit_compute_dtype=torch.bfloat16
    )
    # Load the model
    print("Loading model...")
    model = Qwen2VLForConditionalGeneration.from_pretrained(
        pretrained_model_name_or_path=f"{MODEL_ORG_NAME}/{MODEL_NAME}",
        device_map="auto",
        torch_dtype=torch.bfloat16,
        quantization_config=bnb_config,
    )
    print("Loading processor...")
    global processor
    processor = Qwen2VLProcessor.from_pretrained(
        f"{MODEL_ORG_NAME}/{MODEL_NAME}",
        min_pixels=256*28*28,  # Minimum number of pixels (256 tokens)
        max_pixels=384*28*28   # Maximum number of pixels (384 tokens instead of 1024 for memory savings)
    )

    # Configure QLoRA (Unlike standard LoRA, which reduces memory by applying a low-rank approximation,
    # takes it a step further by quantizing the weights of the LoRA adapters, leading to even lower memory requirements)
    peft_config = LoraConfig(
        lora_alpha=16,
        lora_dropout=0.05,
        r=8,
        bias="none",
        target_modules=["q_proj", "v_proj"],
        task_type="CAUSAL_LM"
    )

    # Apply PEFT model adaptation
    peft_model = get_peft_model(model, peft_config)

    # Print the trainable parameters
    peft_model.print_trainable_parameters()

    # Configure training arguments
    now = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    training_args = SFTConfig(
        output_dir="qwen2-7b-instruct-trl-sft-ADMIRE",  # Directory to save the model
        num_train_epochs=3,  # Number of training epochs
        per_device_train_batch_size=1,  # Batch size for training
        per_device_eval_batch_size=1,  # Batch size for evaluation
        gradient_accumulation_steps=8,  # Steps to accumulate gradients
        gradient_checkpointing=True,  # Enable gradient checkpointing for memory efficiency
        # Optimizer and scheduler settings
        optim="adamw_torch_fused",  # Optimizer type
        learning_rate=2e-4,  # Learning rate for training
        lr_scheduler_type="constant",  # Type of learning rate scheduler
        # Logging and evaluation
        logging_steps=10,  # Steps interval for logging
        eval_steps=20,  # Steps interval for evaluation
        eval_strategy="steps",  # Strategy for evaluation
        save_strategy="steps",  # Strategy for saving the model
        save_steps=20,  # Steps interval for saving
        metric_for_best_model="eval_loss",  # Metric to evaluate the best model
        greater_is_better=False,  # Whether higher metric values are better
        load_best_model_at_end=True,  # Load the best model after training
        # Mixed precision and gradient settings
        bf16=True,  # Use bfloat16 precision
        tf32=True,  # Use TensorFloat-32 precision
        max_grad_norm=0.3,  # Maximum norm for gradient clipping
        warmup_ratio=0.03,  # Ratio of total steps for warmup
        # Hub and reporting
        push_to_hub=True,  # Whether to push model to Hugging Face Hub
        hub_model_id=f"UCSC-Admire/Qwen2-VL-7B-Instruct-finetune-{now}",
        hub_token=hf_token,
        report_to="wandb",  # Reporting tool for tracking metrics
        # Gradient checkpointing settings
        gradient_checkpointing_kwargs={"use_reentrant": False},  # Options for gradient checkpointing
        # Dataset configuration
        dataset_text_field="",  # Text field in dataset
        dataset_kwargs={"skip_prepare_dataset": True},  # Additional dataset options
        # max_seq_length=1024  # Maximum sequence length for input
    )
    training_args.remove_unused_columns = False  # Keep unused columns in dataset

    # Conecting to weights and biases
    wandb.init(
        project="qwen2-7b-instruct-trl-sft",
        name=f"qwen2-7b-instruct-trl-sft-{now}",
        config=training_args
    )

    # Try generating text from a sample, does it work? Yes!
    sample = train_dataset[0]
    generated_text = generate_text_from_sample(peft_model, processor, sample)
    print(generated_text)

    trainer = SFTTrainer(
        model=peft_model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        data_collator=collate_fn,
        # peft_config=peft_config, # It seems you can either pass the model + peft config or peft_model (Their way in the tutorial isn't obviously supported from the @HFQwen tutorial)
        tokenizer=processor.tokenizer,
    )

    # Train the model!
    print("Training the model...")
    trainer.train()

    print(f"Saving model to {training_args.output_dir}...")
    trainer.save_model(training_args.output_dir)

Full output:
(venv) sam@pop-os:~/code/ucsc/243/admire/admire-finetuning-sam$ /home/sam/code/ucsc/243/admire/admire-finetuning-sam/venv/bin/python /home/sam/code/ucsc/243/admire/admire-finetuning-sam/v2/train.py
Loading dataset...
Dataset size: 3996
Processing datasets...
Processing train data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3796/3796 [03:34<00:00, 17.71it/s]
Processing eval data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:11<00:00, 17.40it/s]
Loading model...
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.16it/s]
Loading processor...
trainable params: 2,523,136 || all params: 8,293,898,752 || trainable%: 0.0304
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: sam-silver. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /home/sam/code/ucsc/243/admire/admire-finetuning-sam/wandb/run-20241204_020826-x017i311
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qwen2-7b-instruct-trl-sft-2024-12-04_02-08-26
wandb: ⭐️ View project at https://wandb.ai/sam-silver/qwen2-7b-instruct-trl-sft
wandb: 🚀 View run at https://wandb.ai/sam-silver/qwen2-7b-instruct-trl-sft/runs/x017i311
E, B, C, A, D
/home/sam/code/ucsc/243/admire/admire-finetuning-sam/venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024
  warnings.warn(
/home/sam/code/ucsc/243/admire/admire-finetuning-sam/venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.
  warnings.warn(
Training the model...
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                            | 0/1422 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
{'loss': 14.5599, 'grad_norm': 34.986446380615234, 'learning_rate': 0.0002, 'epoch': 0.02}                                                                                
{'loss': 11.969, 'grad_norm': 41.593055725097656, 'learning_rate': 0.0002, 'epoch': 0.04}                                                                                 
{'eval_loss': 10.192072868347168, 'eval_runtime': 216.9975, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.04}                              
{'loss': 9.1731, 'grad_norm': 23.609970092773438, 'learning_rate': 0.0002, 'epoch': 0.06}                                                                                 
{'loss': 7.7688, 'grad_norm': 9.070549011230469, 'learning_rate': 0.0002, 'epoch': 0.08}                                                                                  
{'eval_loss': 7.394049167633057, 'eval_runtime': 216.4574, 'eval_samples_per_second': 0.924, 'eval_steps_per_second': 0.924, 'epoch': 0.08}                               
{'loss': 7.2259, 'grad_norm': 3.8098530769348145, 'learning_rate': 0.0002, 'epoch': 0.11}                                                                                 
{'loss': 6.9608, 'grad_norm': 3.804227590560913, 'learning_rate': 0.0002, 'epoch': 0.13}                                                                                  
  4%|█████▍                                                                                                                           | 60/1422 [18:37<4:19:58, 11.45s/it]
 40%|█████████████████████████████████████████████████████▍                                                                              | 81/200 [01:27<02:
 41%|████████████████▍                       | 82/200 [01:28<02:12,  1.13s/it]                                                                                                                                                            {'eval_loss': 6.836002349853516, 'eval_runtime': 218.5503, 'eval_samples_per_second': 0.915, 'eval_steps_per_second': 0.915, 'epoch': 0.13}                 
{'loss': 6.7791, 'grad_norm': 1.8830714225769043, 'learning_rate': 0.0002, 'epoch': 0.15}                                                                   
{'loss': 6.705, 'grad_norm': 1.4071476459503174, 'learning_rate': 0.0002, 'epoch': 0.17}
{'eval_loss': 6.676995277404785, 'eval_runtime': 217.7209, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 0.17}                 
{'loss': 6.664, 'grad_norm': 1.7235758304595947, 'learning_rate': 0.0002, 'epoch': 0.19}                                                                    
{'loss': 6.6296, 'grad_norm': 1.2654249668121338, 'learning_rate': 0.0002, 'epoch': 0.21}
{'eval_loss': 6.618938446044922, 'eval_runtime': 217.5722, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 0.21}                 
{'loss': 6.6085, 'grad_norm': 1.3803859949111938, 'learning_rate': 0.0002, 'epoch': 0.23}                                                                   
{'loss': 6.5978, 'grad_norm': 1.1433502435684204, 'learning_rate': 0.0002, 'epoch': 0.25}
{'eval_loss': 6.59084415435791, 'eval_runtime': 217.3591, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 0.25}                    
{'loss': 6.5862, 'grad_norm': 1.373647689819336, 'learning_rate': 0.0002, 'epoch': 0.27}                                                                    
{'loss': 6.5767, 'grad_norm': 0.8999692797660828, 'learning_rate': 0.0002, 'epoch': 0.3}
{'eval_loss': 6.574965953826904, 'eval_runtime': 217.6695, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 0.3}                  
{'loss': 6.5755, 'grad_norm': 0.8763388395309448, 'learning_rate': 0.0002, 'epoch': 0.32}                                                                   
{'loss': 6.5657, 'grad_norm': 1.1560187339782715, 'learning_rate': 0.0002, 'epoch': 0.34}
{'eval_loss': 6.566245079040527, 'eval_runtime': 216.8846, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.34}                 
{'loss': 6.5652, 'grad_norm': 0.8728417754173279, 'learning_rate': 0.0002, 'epoch': 0.36}                                                                   
{'loss': 6.5624, 'grad_norm': 0.8472049236297607, 'learning_rate': 0.0002, 'epoch': 0.38}
{'eval_loss': 6.560461521148682, 'eval_runtime': 217.5198, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 0.38}                 
{'loss': 6.5611, 'grad_norm': 0.8779647946357727, 'learning_rate': 0.0002, 'epoch': 0.4}                                                                    
{'loss': 6.5617, 'grad_norm': 1.6122158765792847, 'learning_rate': 0.0002, 'epoch': 0.42}
{'eval_loss': 6.558502197265625, 'eval_runtime': 216.8722, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.42}                 
{'loss': 6.5584, 'grad_norm': 0.887953519821167, 'learning_rate': 0.0002, 'epoch': 0.44}                                                                    
{'loss': 6.5576, 'grad_norm': 1.9873360395431519, 'learning_rate': 0.0002, 'epoch': 0.46}
{'eval_loss': 6.554995536804199, 'eval_runtime': 216.9772, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.46}                 
{'loss': 6.554, 'grad_norm': 0.884396493434906, 'learning_rate': 0.0002, 'epoch': 0.48}                                                                     
{'loss': 6.557, 'grad_norm': 1.0201518535614014, 'learning_rate': 0.0002, 'epoch': 0.51}
{'eval_loss': 6.552361965179443, 'eval_runtime': 217.2781, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 0.51}                   
{'loss': 6.555, 'grad_norm': 1.0064772367477417, 'learning_rate': 0.0002, 'epoch': 0.53}                                                                    
{'loss': 6.5536, 'grad_norm': 1.1933047771453857, 'learning_rate': 0.0002, 'epoch': 0.55}
{'eval_loss': 6.55119514465332, 'eval_runtime': 217.3754, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 0.55}                    
{'loss': 6.549, 'grad_norm': 1.6864283084869385, 'learning_rate': 0.0002, 'epoch': 0.57}                                                                    
{'loss': 6.5498, 'grad_norm': 0.8392448425292969, 'learning_rate': 0.0002, 'epoch': 0.59}
{'eval_loss': 6.549632549285889, 'eval_runtime': 216.8917, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.59}                 
{'loss': 6.5487, 'grad_norm': 0.6557180881500244, 'learning_rate': 0.0002, 'epoch': 0.61}                                                                   
{'loss': 6.5481, 'grad_norm': 1.028131127357483, 'learning_rate': 0.0002, 'epoch': 0.63}
{'eval_loss': 6.548847675323486, 'eval_runtime': 217.5811, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 0.63}                 
{'loss': 6.5476, 'grad_norm': 2.1891446113586426, 'learning_rate': 0.0002, 'epoch': 0.65}                                                                   
{'loss': 6.5495, 'grad_norm': 1.0202306509017944, 'learning_rate': 0.0002, 'epoch': 0.67}
{'eval_loss': 6.54798698425293, 'eval_runtime': 217.1783, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 0.67}                  
{'loss': 6.5477, 'grad_norm': 0.9665899872779846, 'learning_rate': 0.0002, 'epoch': 0.7}                                                                    
{'loss': 6.5512, 'grad_norm': 1.810166358947754, 'learning_rate': 0.0002, 'epoch': 0.72}
{'eval_loss': 6.547818183898926, 'eval_runtime': 216.8225, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.72}                 
{'loss': 6.5437, 'grad_norm': 0.86532062292099, 'learning_rate': 0.0002, 'epoch': 0.74}                                                                     
{'loss': 6.545, 'grad_norm': 1.2096692323684692, 'learning_rate': 0.0002, 'epoch': 0.76}
{'eval_loss': 6.546828746795654, 'eval_runtime': 217.0878, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 0.76}                 
{'loss': 6.5443, 'grad_norm': 1.6057759523391724, 'learning_rate': 0.0002, 'epoch': 0.78}                                                                   
{'loss': 6.5464, 'grad_norm': 1.3156195878982544, 'learning_rate': 0.0002, 'epoch': 0.8}
{'eval_loss': 6.545684814453125, 'eval_runtime': 216.847, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.8}                   
{'loss': 6.5453, 'grad_norm': 1.1898847818374634, 'learning_rate': 0.0002, 'epoch': 0.82}                                                                   
{'loss': 6.5431, 'grad_norm': 0.8452103734016418, 'learning_rate': 0.0002, 'epoch': 0.84}
{'eval_loss': 6.545263290405273, 'eval_runtime': 217.4336, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 0.84}                   
{'loss': 6.5468, 'grad_norm': 0.7921375632286072, 'learning_rate': 0.0002, 'epoch': 0.86}                                                                   
{'loss': 6.5466, 'grad_norm': 0.5913310647010803, 'learning_rate': 0.0002, 'epoch': 0.89}
{'eval_loss': 6.544809341430664, 'eval_runtime': 217.5789, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 0.89}                 
{'loss': 6.5396, 'grad_norm': 1.5439060926437378, 'learning_rate': 0.0002, 'epoch': 0.91}                                                                   
{'loss': 6.5453, 'grad_norm': 1.7771459817886353, 'learning_rate': 0.0002, 'epoch': 0.93}
{'eval_loss': 6.5445709228515625, 'eval_runtime': 217.192, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 0.93}                 
{'loss': 6.5434, 'grad_norm': 0.6397672891616821, 'learning_rate': 0.0002, 'epoch': 0.95}                                                                   
{'loss': 6.5436, 'grad_norm': 0.7425759434700012, 'learning_rate': 0.0002, 'epoch': 0.97}
{'eval_loss': 6.543883800506592, 'eval_runtime': 216.8095, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 0.97}                 
{'loss': 6.5435, 'grad_norm': 0.6350188851356506, 'learning_rate': 0.0002, 'epoch': 0.99}                                                                   
{'loss': 6.5445, 'grad_norm': 0.6900752186775208, 'learning_rate': 0.0002, 'epoch': 1.01}
{'eval_loss': 6.543856143951416, 'eval_runtime': 216.3186, 'eval_samples_per_second': 0.925, 'eval_steps_per_second': 0.925, 'epoch': 1.01}                 
{'loss': 6.5423, 'grad_norm': 0.7928141951560974, 'learning_rate': 0.0002, 'epoch': 1.03}                                                                   
{'loss': 6.5414, 'grad_norm': 0.6406348943710327, 'learning_rate': 0.0002, 'epoch': 1.05}
{'eval_loss': 6.54304313659668, 'eval_runtime': 217.4093, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.05}                    
{'loss': 6.5445, 'grad_norm': 1.5565091371536255, 'learning_rate': 0.0002, 'epoch': 1.07}                                                                   
{'loss': 6.541, 'grad_norm': 2.135701894760132, 'learning_rate': 0.0002, 'epoch': 1.1}
{'eval_loss': 6.542945384979248, 'eval_runtime': 217.4922, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.1}                    
{'loss': 6.5423, 'grad_norm': 0.9600397944450378, 'learning_rate': 0.0002, 'epoch': 1.12}                                                                   
{'loss': 6.5436, 'grad_norm': 0.8412309288978577, 'learning_rate': 0.0002, 'epoch': 1.14}
{'eval_loss': 6.542717933654785, 'eval_runtime': 216.7765, 'eval_samples_per_second': 0.923, 'eval_steps_per_second': 0.923, 'epoch': 1.14}                 
{'loss': 6.5438, 'grad_norm': 0.9565261006355286, 'learning_rate': 0.0002, 'epoch': 1.16}                                                                   
{'loss': 6.5409, 'grad_norm': 0.85605788230896, 'learning_rate': 0.0002, 'epoch': 1.18}
{'eval_loss': 6.541419506072998, 'eval_runtime': 217.5713, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 1.18}                 
{'loss': 6.5394, 'grad_norm': 0.6049232482910156, 'learning_rate': 0.0002, 'epoch': 1.2}                                                                    
{'loss': 6.5441, 'grad_norm': 1.7690421342849731, 'learning_rate': 0.0002, 'epoch': 1.22}
{'eval_loss': 6.542033672332764, 'eval_runtime': 217.4841, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.22}                   
{'loss': 6.5418, 'grad_norm': 0.9066015481948853, 'learning_rate': 0.0002, 'epoch': 1.24}                                                                   
{'loss': 6.5389, 'grad_norm': 0.8122724890708923, 'learning_rate': 0.0002, 'epoch': 1.26}
{'eval_loss': 6.541242599487305, 'eval_runtime': 217.4131, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.26}                   
{'loss': 6.5405, 'grad_norm': 0.7895008325576782, 'learning_rate': 0.0002, 'epoch': 1.29}                                                                   
{'loss': 6.5422, 'grad_norm': 1.7510417699813843, 'learning_rate': 0.0002, 'epoch': 1.31}
{'eval_loss': 6.5413103103637695, 'eval_runtime': 216.3576, 'eval_samples_per_second': 0.924, 'eval_steps_per_second': 0.924, 'epoch': 1.31}                
{'loss': 6.5366, 'grad_norm': 0.7941744923591614, 'learning_rate': 0.0002, 'epoch': 1.33}                                                                   
{'loss': 6.5413, 'grad_norm': 0.7577549815177917, 'learning_rate': 0.0002, 'epoch': 1.35}
{'eval_loss': 6.540406703948975, 'eval_runtime': 217.4549, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.35}                   
{'loss': 6.5474, 'grad_norm': 1.108428716659546, 'learning_rate': 0.0002, 'epoch': 1.37}                                                                    
{'loss': 6.5347, 'grad_norm': 1.2479267120361328, 'learning_rate': 0.0002, 'epoch': 1.39}
{'eval_loss': 6.540256500244141, 'eval_runtime': 217.6427, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 1.39}                 
{'loss': 6.5378, 'grad_norm': 0.6393293142318726, 'learning_rate': 0.0002, 'epoch': 1.41}                                                                   
{'loss': 6.5368, 'grad_norm': 1.7365397214889526, 'learning_rate': 0.0002, 'epoch': 1.43}
{'eval_loss': 6.539330959320068, 'eval_runtime': 216.986, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 1.43}                  
{'loss': 6.5402, 'grad_norm': 0.9725116491317749, 'learning_rate': 0.0002, 'epoch': 1.45}                                                                   
{'loss': 6.5381, 'grad_norm': 0.7056076526641846, 'learning_rate': 0.0002, 'epoch': 1.48}
{'eval_loss': 6.538913726806641, 'eval_runtime': 217.4157, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.48}                   
{'loss': 6.5366, 'grad_norm': 0.6957536935806274, 'learning_rate': 0.0002, 'epoch': 1.5}                                                                    
{'loss': 6.5361, 'grad_norm': 0.7672606706619263, 'learning_rate': 0.0002, 'epoch': 1.52}
{'eval_loss': 6.538872718811035, 'eval_runtime': 217.0916, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 1.52}                 
{'loss': 6.5384, 'grad_norm': 1.8489184379577637, 'learning_rate': 0.0002, 'epoch': 1.54}                                                                   
{'loss': 6.5411, 'grad_norm': 1.3434791564941406, 'learning_rate': 0.0002, 'epoch': 1.56}
{'eval_loss': 6.538256645202637, 'eval_runtime': 216.2692, 'eval_samples_per_second': 0.925, 'eval_steps_per_second': 0.925, 'epoch': 1.56}                 
{'loss': 6.538, 'grad_norm': 1.0617250204086304, 'learning_rate': 0.0002, 'epoch': 1.58}                                                                    
{'loss': 6.5368, 'grad_norm': 1.1498390436172485, 'learning_rate': 0.0002, 'epoch': 1.6}
{'eval_loss': 6.53839111328125, 'eval_runtime': 216.9472, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 1.6}                   
{'loss': 6.5415, 'grad_norm': 0.7946908473968506, 'learning_rate': 0.0002, 'epoch': 1.62}                                                                   
{'loss': 6.542, 'grad_norm': 0.6868600249290466, 'learning_rate': 0.0002, 'epoch': 1.64}
{'eval_loss': 6.537642955780029, 'eval_runtime': 217.292, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.64}                    
{'loss': 6.5345, 'grad_norm': 0.7983841300010681, 'learning_rate': 0.0002, 'epoch': 1.66}                                                                   
{'loss': 6.5375, 'grad_norm': 0.5471001863479614, 'learning_rate': 0.0002, 'epoch': 1.69}
{'eval_loss': 6.537357330322266, 'eval_runtime': 217.3439, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.69}                   
{'loss': 6.5359, 'grad_norm': 0.6578023433685303, 'learning_rate': 0.0002, 'epoch': 1.71}                                                                   
{'loss': 6.5385, 'grad_norm': 0.5735700726509094, 'learning_rate': 0.0002, 'epoch': 1.73}
{'eval_loss': 6.537294864654541, 'eval_runtime': 217.037, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 1.73}                  
{'loss': 6.5375, 'grad_norm': 1.0897740125656128, 'learning_rate': 0.0002, 'epoch': 1.75}                                                                   
{'loss': 6.5378, 'grad_norm': 0.8301168084144592, 'learning_rate': 0.0002, 'epoch': 1.77}
{'eval_loss': 6.536708354949951, 'eval_runtime': 216.8502, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 1.77}                 
{'loss': 6.5341, 'grad_norm': 0.8333432674407959, 'learning_rate': 0.0002, 'epoch': 1.79}                                                                   
{'loss': 6.5306, 'grad_norm': 0.8477818965911865, 'learning_rate': 0.0002, 'epoch': 1.81}
{'eval_loss': 6.536574840545654, 'eval_runtime': 217.3991, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.81}                   
{'loss': 6.5374, 'grad_norm': 1.0242862701416016, 'learning_rate': 0.0002, 'epoch': 1.83}                                                                   
{'loss': 6.5316, 'grad_norm': 1.3376548290252686, 'learning_rate': 0.0002, 'epoch': 1.85}
{'eval_loss': 6.535946846008301, 'eval_runtime': 217.3853, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.85}                   
{'loss': 6.538, 'grad_norm': 1.4064669609069824, 'learning_rate': 0.0002, 'epoch': 1.88}                                                                    
{'loss': 6.5338, 'grad_norm': 0.9091357588768005, 'learning_rate': 0.0002, 'epoch': 1.9}
{'eval_loss': 6.535383224487305, 'eval_runtime': 217.4253, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.9}                    
{'loss': 6.5319, 'grad_norm': 1.1205101013183594, 'learning_rate': 0.0002, 'epoch': 1.92}                                                                   
{'loss': 6.5347, 'grad_norm': 0.8652428388595581, 'learning_rate': 0.0002, 'epoch': 1.94}
{'eval_loss': 6.535790920257568, 'eval_runtime': 217.6216, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 1.94}                 
{'loss': 6.5312, 'grad_norm': 1.1067525148391724, 'learning_rate': 0.0002, 'epoch': 1.96}                                                                   
{'loss': 6.533, 'grad_norm': 1.629784345626831, 'learning_rate': 0.0002, 'epoch': 1.98}
{'eval_loss': 6.534569263458252, 'eval_runtime': 217.4308, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 1.98}                   
{'loss': 6.5336, 'grad_norm': 0.6292194128036499, 'learning_rate': 0.0002, 'epoch': 2.0}                                                                    
{'loss': 6.534, 'grad_norm': 0.6860976219177246, 'learning_rate': 0.0002, 'epoch': 2.02}
{'eval_loss': 6.534357070922852, 'eval_runtime': 215.7078, 'eval_samples_per_second': 0.927, 'eval_steps_per_second': 0.927, 'epoch': 2.02}                 
{'loss': 6.5338, 'grad_norm': 0.7156447768211365, 'learning_rate': 0.0002, 'epoch': 2.04}                                                                   
{'loss': 6.5338, 'grad_norm': 1.3718966245651245, 'learning_rate': 0.0002, 'epoch': 2.07}
{'eval_loss': 6.534129619598389, 'eval_runtime': 216.5097, 'eval_samples_per_second': 0.924, 'eval_steps_per_second': 0.924, 'epoch': 2.07}                 
{'loss': 6.5321, 'grad_norm': 1.0382860898971558, 'learning_rate': 0.0002, 'epoch': 2.09}                                                                   
{'loss': 6.5357, 'grad_norm': 1.1995114088058472, 'learning_rate': 0.0002, 'epoch': 2.11}
{'eval_loss': 6.533881664276123, 'eval_runtime': 217.6673, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.11}                 
{'loss': 6.5325, 'grad_norm': 1.2206414937973022, 'learning_rate': 0.0002, 'epoch': 2.13}                                                                   
{'loss': 6.5304, 'grad_norm': 0.7350754141807556, 'learning_rate': 0.0002, 'epoch': 2.15}
{'eval_loss': 6.533408164978027, 'eval_runtime': 217.1263, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 2.15}                 
{'loss': 6.5301, 'grad_norm': 0.7390842437744141, 'learning_rate': 0.0002, 'epoch': 2.17}                                                                   
{'loss': 6.5264, 'grad_norm': 0.9482393860816956, 'learning_rate': 0.0002, 'epoch': 2.19}
{'eval_loss': 6.533235549926758, 'eval_runtime': 217.5955, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.19}                 
{'loss': 6.5359, 'grad_norm': 0.6184854507446289, 'learning_rate': 0.0002, 'epoch': 2.21}                                                                   
{'loss': 6.5322, 'grad_norm': 1.4181545972824097, 'learning_rate': 0.0002, 'epoch': 2.23}
{'eval_loss': 6.5335373878479, 'eval_runtime': 216.9491, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 2.23}                   
{'loss': 6.5309, 'grad_norm': 1.2800315618515015, 'learning_rate': 0.0002, 'epoch': 2.26}                                                                   
{'loss': 6.5351, 'grad_norm': 1.4293321371078491, 'learning_rate': 0.0002, 'epoch': 2.28}
{'eval_loss': 6.533237457275391, 'eval_runtime': 217.3993, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 2.28}                   
{'loss': 6.5286, 'grad_norm': 1.5379154682159424, 'learning_rate': 0.0002, 'epoch': 2.3}                                                                    
{'loss': 6.5303, 'grad_norm': 0.663162112236023, 'learning_rate': 0.0002, 'epoch': 2.32}
{'eval_loss': 6.532265663146973, 'eval_runtime': 217.4974, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 2.32}                   
{'loss': 6.5256, 'grad_norm': 0.9713095426559448, 'learning_rate': 0.0002, 'epoch': 2.34}                                                                   
{'loss': 6.5311, 'grad_norm': 0.8099871277809143, 'learning_rate': 0.0002, 'epoch': 2.36}
{'eval_loss': 6.532486438751221, 'eval_runtime': 217.5958, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.36}                 
{'loss': 6.5299, 'grad_norm': 1.3413586616516113, 'learning_rate': 0.0002, 'epoch': 2.38}                                                                   
{'loss': 6.5275, 'grad_norm': 0.82642662525177, 'learning_rate': 0.0002, 'epoch': 2.4}
{'eval_loss': 6.531784534454346, 'eval_runtime': 217.2396, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 2.4}                  
{'loss': 6.5252, 'grad_norm': 1.1090617179870605, 'learning_rate': 0.0002, 'epoch': 2.42}                                                                   
{'loss': 6.5282, 'grad_norm': 1.11593759059906, 'learning_rate': 0.0002, 'epoch': 2.44}
{'eval_loss': 6.5317606925964355, 'eval_runtime': 216.8671, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 2.44}                
{'loss': 6.5291, 'grad_norm': 1.130672812461853, 'learning_rate': 0.0002, 'epoch': 2.47}                                                                    
{'loss': 6.5307, 'grad_norm': 0.7365561127662659, 'learning_rate': 0.0002, 'epoch': 2.49}
{'eval_loss': 6.532050609588623, 'eval_runtime': 217.5747, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.49}                 
{'loss': 6.5351, 'grad_norm': 0.7338492274284363, 'learning_rate': 0.0002, 'epoch': 2.51}                                                                   
{'loss': 6.532, 'grad_norm': 1.5010712146759033, 'learning_rate': 0.0002, 'epoch': 2.53}
{'eval_loss': 6.531328201293945, 'eval_runtime': 217.4211, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 2.53}                   
{'loss': 6.5313, 'grad_norm': 0.6248738765716553, 'learning_rate': 0.0002, 'epoch': 2.55}                                                                   
{'loss': 6.5279, 'grad_norm': 1.0312798023223877, 'learning_rate': 0.0002, 'epoch': 2.57}
{'eval_loss': 6.530960559844971, 'eval_runtime': 217.5717, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.57}                 
{'loss': 6.5272, 'grad_norm': 1.133689045906067, 'learning_rate': 0.0002, 'epoch': 2.59}                                                                    
{'loss': 6.5266, 'grad_norm': 0.9953656792640686, 'learning_rate': 0.0002, 'epoch': 2.61}    
{'eval_loss': 6.530604362487793, 'eval_runtime': 217.5898, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.61}                                               
{'loss': 6.5298, 'grad_norm': 0.8895167708396912, 'learning_rate': 0.0002, 'epoch': 2.63}    
{'loss': 6.5238, 'grad_norm': 1.3413070440292358, 'learning_rate': 0.0002, 'epoch': 2.66}    
{'eval_loss': 6.530261039733887, 'eval_runtime': 217.2515, 'eval_samples_per_second': 0.921, 'eval_steps_per_second': 0.921, 'epoch': 2.66}                                               
{'loss': 6.5277, 'grad_norm': 0.719389021396637, 'learning_rate': 0.0002, 'epoch': 2.68}     
{'loss': 6.524, 'grad_norm': 1.0999243259429932, 'learning_rate': 0.0002, 'epoch': 2.7}      
{'eval_loss': 6.530245780944824, 'eval_runtime': 217.4823, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 2.7}                                                  
{'loss': 6.5324, 'grad_norm': 0.9612635970115662, 'learning_rate': 0.0002, 'epoch': 2.72}    
{'loss': 6.5314, 'grad_norm': 1.260728359222412, 'learning_rate': 0.0002, 'epoch': 2.74}     
{'eval_loss': 6.530467510223389, 'eval_runtime': 217.6215, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.74}                                               
{'loss': 6.526, 'grad_norm': 0.8748852014541626, 'learning_rate': 0.0002, 'epoch': 2.76}     
{'loss': 6.5269, 'grad_norm': 0.7283299565315247, 'learning_rate': 0.0002, 'epoch': 2.78}    
{'eval_loss': 6.529399394989014, 'eval_runtime': 217.7479, 'eval_samples_per_second': 0.918, 'eval_steps_per_second': 0.918, 'epoch': 2.78}                                               
{'loss': 6.5283, 'grad_norm': 1.1132663488388062, 'learning_rate': 0.0002, 'epoch': 2.8}     
{'loss': 6.5268, 'grad_norm': 1.1551218032836914, 'learning_rate': 0.0002, 'epoch': 2.82}    
{'eval_loss': 6.529361724853516, 'eval_runtime': 217.632, 'eval_samples_per_second': 0.919, 'eval_steps_per_second': 0.919, 'epoch': 2.82}                                                
{'loss': 6.5268, 'grad_norm': 0.7027749419212341, 'learning_rate': 0.0002, 'epoch': 2.85}    
{'loss': 6.5274, 'grad_norm': 0.8180713653564453, 'learning_rate': 0.0002, 'epoch': 2.87}    
{'eval_loss': 6.5292649269104, 'eval_runtime': 217.9927, 'eval_samples_per_second': 0.917, 'eval_steps_per_second': 0.917, 'epoch': 2.87}                                                 
{'loss': 6.5312, 'grad_norm': 1.0311928987503052, 'learning_rate': 0.0002, 'epoch': 2.89}    
{'loss': 6.5255, 'grad_norm': 0.7630473375320435, 'learning_rate': 0.0002, 'epoch': 2.91}    
{'eval_loss': 6.528496265411377, 'eval_runtime': 217.4717, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 2.91}                                                 
{'loss': 6.5274, 'grad_norm': 0.851813554763794, 'learning_rate': 0.0002, 'epoch': 2.93}     
{'loss': 6.5287, 'grad_norm': 0.6172767877578735, 'learning_rate': 0.0002, 'epoch': 2.95}    
{'eval_loss': 6.528192043304443, 'eval_runtime': 216.9812, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 2.95}                                               
{'loss': 6.5283, 'grad_norm': 1.0193049907684326, 'learning_rate': 0.0002, 'epoch': 2.97}    
{'loss': 6.5277, 'grad_norm': 1.0454150438308716, 'learning_rate': 0.0002, 'epoch': 2.99}    
{'eval_loss': 6.527688980102539, 'eval_runtime': 218.3081, 'eval_samples_per_second': 0.916, 'eval_steps_per_second': 0.916, 'epoch': 2.99}                                                 
{'train_runtime': 31666.0133, 'train_samples_per_second': 0.36, 'train_steps_per_second': 0.045, 'train_loss': 6.673980739716907, 'epoch': 3.0}                                             
100%|███████████████████████████████████████████████████| 1422/1422 [8:47:46<00:00, 22.27s/it]
Saving model to qwen2-7b-instruct-trl-sft-ADMIRE...
DONE!

Let's analyze the training run with Sonnet:
Training Progress:
Started with high loss (~14.5) and quickly dropped to ~6.5 in the first epoch
Stabilized around 6.52-6.54 for most of training
Final training loss: 6.67
Final eval loss: 6.527
Training took about 8 hours and 47 minutes
The loss reduction and stabilization pattern suggests the model was learning, but the relatively small improvement in later epochs might indicate we could have used a lower learning rate or fewer epochs. However, this kind of plateau is not unusual for large language models, especially when fine-tuning with LoRA.
Warnings to Note:
There was a warning about max_seq_length not being set (defaulting to 1024)
A warning about padding_side not being "right" which could affect training stability
These aren't critical but might be worth addressing in future runs
Regarding HuggingFace Upload:
Only the LoRA adapters were saved and pushed to HuggingFace, not the full model. This is because:
You used PEFT/LoRA configuration
The base model (Qwen2-VL-7B) is too large (~7B parameters)
The LoRA adapters contain just the trained differences from the base model
To use the fine-tuned model, someone would need to:
Load the base Qwen2-VL-7B model
Load your LoRA adapters from HuggingFace
Merge them (or use them in inference mode without merging)
The adapters are much smaller (your trainable params were only 0.0304% of the full model, or about 2.5M parameters), making them easy to share and version control.
Would you like me to suggest any improvements for future training runs based on these results


Great, now let's evaluate it on the test set, versus the base quantized model:

(venv) sam@pop-os:~/code/ucsc/243/admire/admire-finetuning-sam$  cd /home/sam/code/ucsc/243/admire/admire-finetuning-sam ; /usr/bin/env /home/sam/code/ucsc/243/admire/admire-finetuning-sam/venv/bin/python /home/sam/.cursor/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher 52523 -- /home/sam/code/ucsc/243/admire/admire-finetuning-sam/v2/evaluation.py 
Loading test dataset...
Test dataset size: 444
Loading base model...
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.08it/s]
Loading finetuned model...
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.98it/s]

Evaluating base model...
Evaluating base model: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 444/444 [11:12<00:00,  1.52s/it]

Evaluating finetuned model...
Evaluating finetuned model: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 444/444 [11:52<00:00,  1.61s/it]

Evaluation Results:
==================================================
Base Model:
Top-1 Accuracy: 0.2050
Spearman Correlation: -0.0239
--------------------------------------------------
Finetuned Model:
Top-1 Accuracy: 0.2252
Spearman Correlation: 0.0588
==================================================


-----------
Okay, I'm curious if I was overfitting at all.
Let's see what we might want to change
-----------

Based on your training results and evaluation metrics, here are several suggestions to potentially improve the model's performance:
Learning Rate Schedule:
training_args = SFTConfig(
    # ... existing args ...
    learning_rate=2e-4,  # Try reducing to 1e-4 or 5e-5
    lr_scheduler_type="cosine_with_restarts",  # Change from "constant"
    num_train_epochs=5,  # Increase epochs since we're using a better scheduler
    warmup_ratio=0.1,  # Increase from 0.03 for more stable initial training
)
Gradient Accumulation and Batch Size:
training_args = SFTConfig(
    # ... existing args ...
    per_device_train_batch_size=1,
    gradient_accumulation_steps=16,  # Increase from 8 for more stable updates
    max_grad_norm=1.0,  # Increase from 0.3 for less aggressive clipping
)
LoRA Configuration:
peft_config = LoraConfig(
    r=32,  # Increase from 16 for more capacity
    lora_alpha=32,  # Keep alpha = r
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],  # Be more specific about which layers to tune
    bias="none",
    task_type="CAUSAL_LM"
)
Data Processing:
def format_data(sample: dict) -> list[dict]:
    """Enhanced data formatting"""
    images = [sample[f"image_{i}"].resize((512, 512)) for i in range(1, 6)]  # Increase resolution
    
    # Add more context to the instruction
    instruction = f"""You are a helpful assistant that can rank images based on their relevance to a given compound and sentence.
    The compound is: {sample['compound']}
    The sentence using this compound is: {sample['sentence']}
    
    Please rank the five images (labeled A through E) from most to least relevant, considering whether the compound is used literally or idiomatically in the sentence.
    
    Respond with only the ranking in the format: X, Y, Z, W, V where these are the image labels in order from most to least relevant.
    """
    
    # Rest of the function remains the same
Training Stability:
training_args = SFTConfig(
    # ... existing args ...
    fp16=False,  # Disable mixed precision if you see NaN losses
    bf16=True,  # Use bfloat16 instead for better numerical stability
    gradient_checkpointing=True,
    optim="adamw_8bit",
    weight_decay=0.05,  # Increase from 0.01 for better regularization
)
The rationale for these changes:
Your loss plateaued quickly (around 6.5) and stayed there, suggesting the learning rate might be too high or the schedule too simple
The modest improvement in accuracy (20.5% → 22.5%) suggests the model might benefit from more capacity (higher LoRA rank) and more stable training
The Spearman correlation improvement (-.024 → .059) shows the model is learning but could benefit from better regularization and training stability
More explicit instructions and higher resolution images might help the model better understand the task
Would you like me to elaborate on any of these suggestions?

~~~

I'm not going to implement all of these. I'll post what I'm running with for a second run